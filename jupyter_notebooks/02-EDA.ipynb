{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Purple\">Project 3 :  Web APIs & NLP</span> <img src=\"../resources/reddit_logo.png\" width=\"110\" height=\"110\" />\n",
    "---\n",
    "## <span style=\"color:Orange\">EDA </span>      \n",
    "\n",
    "#### Ryan McDonald"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VanLife</td>\n",
       "      <td>Treasure at the end of the rainbow. Gonzaga Ba...</td>\n",
       "      <td>TheKombiChronicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VanLife</td>\n",
       "      <td>Boulder Colorado :)</td>\n",
       "      <td>Germscout805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VanLife</td>\n",
       "      <td>If you like YouTube Poop you're gonna love my ...</td>\n",
       "      <td>roadkamper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VanLife</td>\n",
       "      <td>Love the boondocking near Ventura on the coast</td>\n",
       "      <td>josiahq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VanLife</td>\n",
       "      <td>What is this silver box? It's in a 1992 SMB</td>\n",
       "      <td>lucky2bthe1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>camping</td>\n",
       "      <td>Website for camping?</td>\n",
       "      <td>arstanash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>camping</td>\n",
       "      <td>Camping near Wild Willy's Hot Spring/eastern s...</td>\n",
       "      <td>SpicyChickenDinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>camping</td>\n",
       "      <td>Camping in the boundary waters</td>\n",
       "      <td>_spicygin_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>camping</td>\n",
       "      <td>Favorite camping spot in El Dorado National Fo...</td>\n",
       "      <td>2themoonanback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>camping</td>\n",
       "      <td>Last camp meal of the season was memorable to ...</td>\n",
       "      <td>2themoonanback</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                              title  \\\n",
       "0      VanLife  Treasure at the end of the rainbow. Gonzaga Ba...   \n",
       "1      VanLife                                Boulder Colorado :)   \n",
       "2      VanLife  If you like YouTube Poop you're gonna love my ...   \n",
       "3      VanLife     Love the boondocking near Ventura on the coast   \n",
       "4      VanLife        What is this silver box? It's in a 1992 SMB   \n",
       "...        ...                                                ...   \n",
       "7995   camping                               Website for camping?   \n",
       "7996   camping  Camping near Wild Willy's Hot Spring/eastern s...   \n",
       "7997   camping                     Camping in the boundary waters   \n",
       "7998   camping  Favorite camping spot in El Dorado National Fo...   \n",
       "7999   camping  Last camp meal of the season was memorable to ...   \n",
       "\n",
       "                  author  \n",
       "0     TheKombiChronicles  \n",
       "1           Germscout805  \n",
       "2             roadkamper  \n",
       "3                josiahq  \n",
       "4            lucky2bthe1  \n",
       "...                  ...  \n",
       "7995           arstanash  \n",
       "7996  SpicyChickenDinner  \n",
       "7997          _spicygin_  \n",
       "7998      2themoonanback  \n",
       "7999      2themoonanback  \n",
       "\n",
       "[8000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs =pd.read_csv('../datasets/submissions')\n",
    "subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit    object\n",
       "title        object\n",
       "author       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing 'object datatypes'\n",
    "subs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>7809</td>\n",
       "      <td>5217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>VanLife</td>\n",
       "      <td>survival pen</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4000</td>\n",
       "      <td>5</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit         title     author\n",
       "count       8000          8000       8000\n",
       "unique         2          7809       5217\n",
       "top      VanLife  survival pen  [deleted]\n",
       "freq        4000             5        156"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like some titles aren't unique!\n",
    "subs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survival pen                                                                                5\n",
       "Glamping in Yamanashi, Japan a few weekends ago under a full moon with co-workers.          5\n",
       "Live in 10 minutes                                                                          4\n",
       "Live now                                                                                    4\n",
       "Finishing the last pieces to take the van on its first voyage after 15 years of sitting!    4\n",
       "My camping setup!!                                                                          4\n",
       "The Modern Nomad | Van Life                                                                 4\n",
       "August 2020. Bald Eagle State Forest, PA                                                    4\n",
       "Park Life                                                                                   4\n",
       "Arnous Village,Lebanon.                                                                     4\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some posts are duplicated\n",
    "subs['title'].value_counts(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no missing 'title' entries.\n",
    "subs['title'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanLife    0.5\n",
       "camping    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying equal distribution of data between each subreddit\n",
    "subs['subreddit'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5217"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique authors\n",
    "subs['author'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[deleted]             156\n",
       "vanlifewithgpayne     144\n",
       "ArchieandMe            42\n",
       "drunkbackpacker        27\n",
       "yellowmoose52          21\n",
       "                     ... \n",
       "joannieoconnells14      1\n",
       "Boonina                 1\n",
       "linwemes                1\n",
       "eggzndbacon             1\n",
       "QuietInNature           1\n",
       "Name: author, Length: 5217, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs['author'].value_counts(ascending = False)\n",
    "\n",
    "# the most prolific author was deleted!.. drunkbackpacker???  Haha!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Going to start by breaking the titles down into single sentences for further processing.  If the models don't work as well as they could, further segmentation into smaller/larger groups of words may occur**\n",
    "\n",
    "    - Will breakdown VanLife and camping titles seperately in order to preserve relationship.\n",
    "    - Full lists of titles to be seperated into sentences\n",
    "    - New DataFrame developed with sentence breakdown for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting with VanLife Titles\n",
    "vl_titles = list(subs['title'][0:4000])\n",
    "len(vl_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3485"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VanLife tokenized sentences\n",
    "vl_sent = \" \".join(vl_titles)\n",
    "vl_stoken = sent_tokenize(vl_sent)\n",
    "len(vl_stoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# camping titles\n",
    "vl_titles = list(subs['title'][4000:8000])\n",
    "len(vl_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2886"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# camping tokenized sentences\n",
    "cmp_sent = \" \".join(vl_titles)\n",
    "cmp_stoken = sent_tokenize(cmp_sent)\n",
    "len(cmp_stoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenizing into sentences appears to combine titles here and there, resulting in less unique datapoints. But, may in-turn create a better model**\n",
    "\n",
    "    - Just to have it available, I'll preserve a list of the titles unaltered\n",
    "    \n",
    "**Building a DataFrame with tokenized titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>camping</td>\n",
       "      <td>First tim camping Camping Tricks: A few of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>camping</td>\n",
       "      <td>Last summer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camping</td>\n",
       "      <td>We were playing war.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camping</td>\n",
       "      <td>I caught the moment the cards were read.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>camping</td>\n",
       "      <td>Joshua Tree National Park back country!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title\n",
       "0   camping  First tim camping Camping Tricks: A few of the...\n",
       "1   camping                                       Last summer.\n",
       "2   camping                               We were playing war.\n",
       "3   camping           I caught the moment the cards were read.\n",
       "4   camping            Joshua Tree National Park back country!"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df = pd.DataFrame(\n",
    "    {'subreddit':'camping',\n",
    "    'title': cmp_stoken})\n",
    "vl_df = pd.DataFrame(\n",
    "    {'subreddit':'VanLife',\n",
    "     'title':vl_stoken})\n",
    "\n",
    "token_df = pd.concat([token_df, vl_df], ignore_index= True)\n",
    "token_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6371, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV!\n",
    "\n",
    "token_df.to_csv('../datasets/tokenized_df', index= False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Score\n",
    "**With the amount of data pulled from Reddit, and the low baseline score, I would expect modeling to perform much better**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanLife    0.54701\n",
       "camping    0.45299\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df['subreddit'].value_counts(normalize= True)\n",
    "# This will show baseline 'majority' case.  \n",
    "# 'Guessing' VanLife each time would be correct 54.4% of the time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I prefer to start off with the tokenized sentences because it skews the originally-normalized data.  Having this baseline score in VanLife's favor may product more interesting results down the line**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Sentiment Check! (curiousity strikes)\n",
    "\n",
    "**Does either subreddit as a whole have a better sentiment analysis?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing as SIA takes 'length' into account when producing results,\n",
    "# this is for 'entertainment' purposes only!\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "vl_text= '-'.join(subs['title'][0:4000])\n",
    "camp_text = '-'.join(subs['title'][4000:8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.031, 'neu': 0.832, 'pos': 0.138, 'compound': 1.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(vl_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.035, 'neu': 0.812, 'pos': 0.153, 'compound': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(camp_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An interesting finding above! Both SubReddits have VERY similar sentiment polarity scores.  Assuming since they are related to each other, and typically involve optimistic people.  That was good to see!.  HOWEVER... to rule out any bias towards total word count, I'll break down the SIA below per title in the DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying SIA to the entire DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4823</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.9739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.9720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.9690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.9669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>0.349</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.8619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.8777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        neg    neu    pos  compound\n",
       "4823  0.000  0.404  0.596    0.9739\n",
       "1953  0.000  0.627  0.373    0.9720\n",
       "5726  0.000  0.619  0.381    0.9690\n",
       "550   0.000  0.504  0.496    0.9669\n",
       "2083  0.000  0.624  0.376    0.9650\n",
       "...     ...    ...    ...       ...\n",
       "7993  0.349  0.651  0.000   -0.8619\n",
       "2239  0.526  0.474  0.000   -0.8750\n",
       "2761  0.526  0.474  0.000   -0.8750\n",
       "1217  0.526  0.474  0.000   -0.8750\n",
       "1789  0.590  0.410  0.000   -0.8777\n",
       "\n",
       "[8000 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = subs['title'].apply(sia.polarity_scores)\n",
    "sentiment_df = pd.DataFrame(sentiment.tolist())\n",
    "sentiment_df.sort_values(by= ['compound'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Sentiment Per Subreddit!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14622314421394667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average VanLife Sentiment:\n",
    "(sentiment_df.loc[0:4000]['compound'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15359095000000042"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average Camping Sentiment:\n",
    "sentiment_df.iloc[4000:8001]['compound'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's not by much, but 'camping' subreddit mean sentiment is higher than 'VanLife' subereddit mean sentiment. Perhaps a few posts regarding broken vans or getting lost were written in the 'VanLife' subreddit!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
