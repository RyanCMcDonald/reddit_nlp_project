{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Purple\">Project 3 :  Web APIs & NLP</span> <img src=\"../resources/reddit_logo.png\" width=\"110\" height=\"110\" />\n",
    "---\n",
    "## <span style=\"color:Orange\">Random Two Similar Subreddit Pulls For Production Model- r/babies and r/houseplants</span>      \n",
    "\n",
    "#### Ryan McDonald, General Assembly <img src=\"../resources/GA.png\" width=\"25\" height=\"25\" />\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model is for presentation use and does not have extended analysis**\n",
    "\n",
    "**My wife is a member of tweo groups, 'babies' and 'houseplants' and claims they talk about the same things...let's test it!**\n",
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Metrics!!!\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## housplants Subreddit\n",
    "### 1. PushShift Loop to Grab houseplants Subreddit Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing the loop through fullsubreddit pages\n",
    "# Default values for 'sort', 'sort_type', and 'size' are good!\n",
    "\n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "def grab_posts (subreddit, last_page =None):\n",
    "    params = {\n",
    "        'subreddit':subreddit,\n",
    "        'before': 1614414483}    \n",
    "# to ensure we pull up mostly the same posts each time, adding a 'before' param! \n",
    "# post pull up until Saturday, February 27, 2021 3:28:03 AM GMT-05:00\n",
    "\n",
    "    if last_page != None:\n",
    "        if len(last_page) > 0:\n",
    "            params['before'] = last_page[-1]['created_utc'] # last posts created timestamp\n",
    "        else:\n",
    "            return []\n",
    "    results = requests.get(url, params)\n",
    "    \n",
    "    return results.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_posts (subreddit, max_submissions = 1000):\n",
    "    \n",
    "    submissions = []         # new list of submissions\n",
    "    last_page = None         # only limiting on # of submissions\n",
    "\n",
    "    # loop incorporated from Alex Patry (textjuicer.com)    \n",
    "    while last_page != [] and len(submissions) < max_submissions:\n",
    "        last_page = grab_posts(subreddit, last_page)\n",
    "        submissions += last_page\n",
    "        time.sleep(1)        # need a 'lag time' between loops\n",
    "    return submissions[:max_submissions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_posts took 64.45196151733398 sec to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "limit_posts = most_posts('houseplants')\n",
    "print ('limit_posts took', time.time() - start_time, 'sec to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(limit_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build DataFrame of Relevant Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "garden = pd.DataFrame(limit_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>My little garden in the living room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>I bought this unknown little cactus and it tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>Just a little elephant ear and beta fish thriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>My plastic box terrarium getting lusher than e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>Opening day at the local greenery, got my hand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                              title\n",
       "0  houseplants                My little garden in the living room\n",
       "1  houseplants  I bought this unknown little cactus and it tur...\n",
       "2  houseplants  Just a little elephant ear and beta fish thriv...\n",
       "3  houseplants  My plastic box terrarium getting lusher than e...\n",
       "4  houseplants  Opening day at the local greenery, got my hand..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "garden = garden[['subreddit','title']]\n",
    "garden.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## babies Subreddit \n",
    "### 1. PushShift Loop to Grab babies Subreddit Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing the loop through fullsubreddit pages\n",
    "# Default values for 'sort', 'sort_type', and 'size' are good!\n",
    "\n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "def grab_posts (subreddit, last_page =None):\n",
    "    params = {\n",
    "        'subreddit':subreddit,\n",
    "        'before': 1614414483}    \n",
    "# to ensure we pull up same posts each time, adding a 'before' param! \n",
    "# post pull up until Saturday, February 27, 2021 3:28:03 AM GMT-05:00\n",
    " \n",
    "    if last_page != None:\n",
    "        if len(last_page) > 0:\n",
    "            params['before'] = last_page[-1]['created_utc'] # last posts created timestamp\n",
    "        else:\n",
    "            return []\n",
    "    results = requests.get(url, params)\n",
    "    \n",
    "    return results.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_posts (subreddit, max_submissions = 1000):\n",
    "    \n",
    "    submissions = []         # new list of submissions\n",
    "    last_page = None         # only limiting on # of submissions\n",
    "\n",
    "    # loop incorporated from Alex Patry (textjuicer.com)      \n",
    "    while last_page != [] and len(submissions) < max_submissions:\n",
    "        last_page = grab_posts(subreddit, last_page)\n",
    "        submissions += last_page\n",
    "        time.sleep(1)        # need a 'lag time' between loops\n",
    "    return submissions[:max_submissions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit_posts took 61.49388146400452  sec to run\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "limit_posts = most_posts('babies')\n",
    "print ('limit_posts took', time.time() - start_time, ' sec to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(limit_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build DataFrame of Relevant Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby = pd.DataFrame(limit_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babies</td>\n",
       "      <td>Help baby Tucker!, organized by Carrie Boling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>babies</td>\n",
       "      <td>Hello everyone, we're new here. Meet Acelynn!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>babies</td>\n",
       "      <td>On Fridays we wear pretty dresses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>babies</td>\n",
       "      <td>4 month appointment!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>babies</td>\n",
       "      <td>How to calm a fussy baby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                          title\n",
       "0    babies  Help baby Tucker!, organized by Carrie Boling\n",
       "1    babies  Hello everyone, we're new here. Meet Acelynn!\n",
       "2    babies             On Fridays we wear pretty dresses.\n",
       "3    babies                          4 month appointment!!\n",
       "4    babies                       How to calm a fussy baby"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby = baby[['subreddit','title']]\n",
    "baby.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [garden, baby]\n",
    "submissions = pd.concat(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>My little garden in the living room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>I bought this unknown little cactus and it tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>Just a little elephant ear and beta fish thriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>My plastic box terrarium getting lusher than e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houseplants</td>\n",
       "      <td>Opening day at the local greenery, got my hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>babies</td>\n",
       "      <td>this is my little santa babyðŸ’™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>babies</td>\n",
       "      <td>My nephew tries sauerkraut for the first time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>babies</td>\n",
       "      <td>Merry Christmas from my former 24 week old NIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>babies</td>\n",
       "      <td>My favorite pirate!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>babies</td>\n",
       "      <td>Snugglepile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit                                              title\n",
       "0    houseplants                My little garden in the living room\n",
       "1    houseplants  I bought this unknown little cactus and it tur...\n",
       "2    houseplants  Just a little elephant ear and beta fish thriv...\n",
       "3    houseplants  My plastic box terrarium getting lusher than e...\n",
       "4    houseplants  Opening day at the local greenery, got my hand...\n",
       "..           ...                                                ...\n",
       "995       babies                      this is my little santa babyðŸ’™\n",
       "996       babies      My nephew tries sauerkraut for the first time\n",
       "997       babies  Merry Christmas from my former 24 week old NIC...\n",
       "998       babies                                My favorite pirate!\n",
       "999       babies                                        Snugglepile\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although my submission pull function has a refernce timer on it (to pull same posts each time), there may still be changes in submissions based on up-voting, deletions, etc.  I will 'hash' out the save_to_csv to ensure data remains frozen for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Running new Data Through the Production Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will begin with a pipeline - CVEC transformer with BernoulliNB estimator\n",
    "# Production model performed 1% better on testing data with the non-sent-tokenized data!\n",
    "\n",
    "X = submissions['title']\n",
    "y = submissions['subreddit']\n",
    "\n",
    "# Subreddit is close to normalized, but will stratify on 'y' as a best practice\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "pipe= Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('bnb', BernoulliNB())])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch through out hyperparameters!\n",
    "# setting up parameter dictionary:\n",
    "\n",
    "pipe_params= {'tf__stop_words':['english', None],     \n",
    "              'tf__ngram_range':[(1, 2), (2,2)],\n",
    "              'tf__analyzer':['word'],\n",
    "              'tf__min_df':[0, 5, 10]       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 12 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8,\n",
       "             estimator=Pipeline(steps=[('tf', TfidfVectorizer()),\n",
       "                                       ('bnb', BernoulliNB())]),\n",
       "             param_grid={'tf__analyzer': ['word'], 'tf__min_df': [0, 5, 10],\n",
       "                         'tf__ngram_range': [(1, 2), (2, 2)],\n",
       "                         'tf__stop_words': ['english', None]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instatiating GridSearchCV\n",
    "\n",
    "gs= GridSearchCV(pipe,\n",
    "                param_grid=pipe_params,\n",
    "                cv=8,                    # 5 fold cross validation\n",
    "                verbose = 1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analysis'></a>\n",
    "### Production Model Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tf__analyzer': 'word',\n",
       " 'tf__min_df': 5,\n",
       " 'tf__ngram_range': (1, 2),\n",
       " 'tf__stop_words': 'english'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Score is: 0.8753333333333333\n",
      "Testing Accuracy Score is: 0.858\n"
     ]
    }
   ],
   "source": [
    "# Score on Training and Testing Data\n",
    "\n",
    "print(f'Training Accuracy Score is: {gs.score(X_train, y_train)}')\n",
    "print(f'Testing Accuracy Score is: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our model succesfully predicted 85.8% of the classes correctly!  Close to our cutoff!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
